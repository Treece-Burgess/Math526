\documentclass[12pt,leqno]{article}
\setlength{\topmargin}{0.0in}
\setlength{\oddsidemargin}{.35in}
%\setlength{\evensidemargin}{.25in}
\setlength{\textwidth}{6.0in}
\setlength{\textheight}{9.50in}
\renewcommand{\baselinestretch}{1.00}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subcaption}
\DeclareMathOperator{\erfc}{erfc}
\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}

%\pagestyle{empty}

\markright{Math 526, Report 1}

\begin{document}
	
	\textbf{\large{Math 526} \hspace{0.5in}  \large{Assignment Report 1}}  \hspace{0.5in}  Anthony Ramirez
	
	\vspace{.25in}
	
	\textbf{\underline{Problem 1:}}
	For this problem, we were given a data set $streambed\_data.mat$ which contains measurements of depth $y$, at position $x$ with $d$, the standard deviation of each depth measurement. We were asked to formulate a Bayesian model employing a Guassian process to estimate the depth profile for this data. We then will use Monte Carlo sampling to characterize our prior and posterior depth profiles. Finally we will compute posterior probabilities that certain points along our cross section have a depth less than 10 feet.
	
	\textbf{Section I}
	
	For this section, we will formulate a model to estimate the depth rofile along the channel's cross-section. Our model is given as
	
	\[ f(\cdot) \sim GP\left( h(\cdot), C(\cdot,\cdot) \right) \]
	\[ y_n | f(\cdot) \sim \mathcal{N}(f(x_n),v_n) \]
	
	where $v_n=d_n^2$ from our data set and we choose $C(x_i,x_j):=\lambda^2 \exp\left( \frac{-(x_i-x_j)^2}{2l^2}\right)$. Since we can choose $h(\cdot)$, we will perform our analysis on two different choices for $h(\cdot)$ given as follows
	
	\[ h_0(x) := 
	\begin{cases}
		-15\exp\left( -\frac{x^2}{1000} \right) & |x| < 40 \\
		0 & otherwise \\
	\end{cases}
	 \]
	
		\[ h_1(x) := 
	\begin{cases}
		-15 + \frac{1}{100}x^2& |x| < 40 \\
		0 & otherwise \\
	\end{cases}
	\]
	
	Both choices of $h(\cdot)$ were constructed so that the dip in our data $y$ is properly captured by the function along with approximately crossing the $x-$axis at $-40$ and $40$. Since our data "looks" symmetric, we want choices that reflect the symmetry we see. The covariance matrix was picked such that we have cintinuity across our points and to establish dependence of the data on its physical position to other data points. We will also make choices for $\lambda, l$, specifically for our analysis, we will use that $(\lambda, l) \in \{1,2,5\}^2$. Based on the discussion in lecture, we know our posterior is given by
	
	\[ f | y_n \sim \mathcal{N}_5 \left( h^{*} +G(y-h^\#), C^{**} - GC^{\#*}\right)\]
	
	Where the exponenents $\#, *$ represent input data and test data respectively thus $G:=C^{*\#}(C^{\#\#}+V^{\#\#})^{-1}$. For clarity, note that
	
	\[ ((C^{**}))_{i,j} = C(x^*_i, x^*_j)\]
	\[ ((C^{*\#}))_{i,j} =((C^{\#*}))_{i,j}^T=C(x^*_i, x^\#_j)\]
	\[((C^{\#\#})_{i,j}=C(x_i,x_j))\]
	\[((V^{\#\#}))_{i,j}=diag(v_1,...,v_n)\]
	
	\newpage
		
	\textbf{Section II}
	
	In this section, we will use Monte Carlo sampling on our prior and generate 10,000 samples. As stated previously, we use two different choices for $h(\cdot)$ in this section along with using all combinations of ${1,2,5}$ for values of $\lambda,l$. The figures below graph these samples along with the mean over all samples pointwise.
	
	\textbf{Section III}
	
	In this section, we will use Monte Carlo sampling on our prior and generate 10,000 samples. As stated previously, we use two different choices for $h(\cdot)$ in this section along with using all combinations of ${1,2,5}$ for values of $\lambda,l$. The figures below graph these samples along with the mean over all samples pointwise. These results are summarized graphically below.
	
	\begin{figure}[htp]
		\centering{\includegraphics[scale=0.5]{HW1part3Y.eps}}
		\label{fig:h0ll1}
		\caption{}
		
		
	\end{figure}

	
	
\end{document}


